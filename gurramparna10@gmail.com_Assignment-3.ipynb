{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <center>Assignment 3</center>"
      ],
      "metadata": {
        "id": "UmcSvO14HgzE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions:"
      ],
      "metadata": {
        "id": "aVQ0_DrKHuBz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Solve below assignment problems in the colab notebook only and submit the same on or before the deadline.\n",
        "* Naming convention for the colab notebook file should be email_assignment_3.ipynb\n",
        "* Do not copy & paste the code from online. If we do so, you will be rewarded with 0 score for the respective question.\n",
        "* If you have any queries, please reach out the assignments channel in Microsoft Teams.\n",
        "* You can refer to online resources for solving these questions but donâ€™t copy the code."
      ],
      "metadata": {
        "id": "z24RkJbLHw4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Problem - 1"
      ],
      "metadata": {
        "id": "lhBmB8N4HyPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def extract_emails(str1):\n",
        "  '''\n",
        "    Define the regular expression to extract all the email addresses from the given string.\n",
        "    INPUT\n",
        "        str1: Input string.\n",
        "    OUTPUT\n",
        "        Return a list of email addresses\n",
        "    \n",
        "    example:\n",
        "    input: \"n20200@rguktn.ac.in and n1208595@rguktn.ac.in are email ids from rguktn domain.\"\n",
        "    output: ['n20200@rguktn.ac.in', 'n1208595@rguktn.ac.in']\n",
        "    \n",
        "    Note: replace the None with output in the return statement.\n",
        "  '''\n",
        "  ### write your code here\n",
        "  emails=re.findall('\\S+@\\S+', str1) \n",
        "  return emails\n",
        "str1=\"s180490@rguktn.ac.in and s180799@rguktn.ac.in are email ids from rguktn domain.\"\n",
        "print(extract_emails(str1))\n",
        " \n",
        "  ### end of code\n",
        " "
      ],
      "metadata": {
        "id": "H-MJxWR5HuZh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f8190ed-e4a1-422d-871a-ba9978e94f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['s180490@rguktn.ac.in', 's180799@rguktn.ac.in']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Problem - 2"
      ],
      "metadata": {
        "id": "TZfKlS0vH6yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def extract_urls(str1):\n",
        "  '''\n",
        "    Define the regular expression to extract all the urls from the given string.\n",
        "    INPUT\n",
        "        str1: Input string.\n",
        "    OUTPUT\n",
        "        Return a list of urls\n",
        "        \n",
        "    Example:\n",
        "    input: \"https://www.ssc.gov.in is the official website for the SSC board\"\n",
        "    output: ['https://www.ssc.gov.in']\n",
        "    \n",
        "    Note: replace the None with output in the return statement.\n",
        "  '''\n",
        "  ### write your code here\n",
        "  urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', str1)\n",
        "  return urls\n",
        "str1=\"https://www.ssc.gov.in is the official website for the SSC board\"\n",
        "print(extract_urls(str1))\n",
        "\n",
        "\n",
        "  ### end of code\n",
        " \n",
        "  "
      ],
      "metadata": {
        "id": "cfXyJlnHH2mC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0af8dec8-610c-42b2-d9d8-e1f9b344b0d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://www.ssc.gov.in']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Problem - 3"
      ],
      "metadata": {
        "id": "6v3Hv3qiH_7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "#nltk.download('punkt')\n",
        "#nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "def remove_stopwords(str1):\n",
        "  '''\n",
        "    Tokenize the given string into words (use regular expressions) and remove the stopwords\n",
        "    INPUT\n",
        "        str1: Input string.\n",
        "    OUTPUT\n",
        "        Return a list of words (except stopwords)\n",
        "    \n",
        "    Example:\n",
        "    input: \"Leg spin to left hander is a bad idea.\"\n",
        "    output: ['Leg', 'spin', 'left', 'hander',  'bad', 'idea']\n",
        "    \n",
        "    Note: \n",
        "      1) HINT: Use stopwords library from nltk.corpus\n",
        "      2) Tokenized words should not contain special characters.\n",
        "      3) Replace the None with output in the return statement.\n",
        "  '''\n",
        "  ### write your code here\n",
        "  pattern= r'\\b\\w+\\b'\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  words = re.findall(pattern,str1.lower())\n",
        "  words=[word for word in words if word.lower() not in stop_words]\n",
        "  return words\n",
        "str1=\"Leg spin to left hander is a bad idea.\"\n",
        "print(remove_stopwords(str1))\n",
        "\n",
        " \n",
        "  ### end of code\n",
        " \n",
        "  "
      ],
      "metadata": {
        "id": "nyb6LTysH8tY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93c66360-e10a-4604-91b8-3f7f63142231"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['leg', 'spin', 'left', 'hander', 'bad', 'idea']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Problem - 4"
      ],
      "metadata": {
        "id": "Z6546SEsIIbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.stem import PorterStemmer\n",
        "def stem_words(str1):\n",
        "  '''\n",
        "    Tokenize the given string into words (use regular expressions), find out the stem of each word and return a list of stem words\n",
        "    INPUT\n",
        "        str1: Input string.\n",
        "    OUTPUT\n",
        "        Return a list of stem words\n",
        "    \n",
        "    Example:\n",
        "    input: \"Jadhav played too slowly.\"\n",
        "    ouput: ['jadhav', 'play', 'too' , 'slowli']\n",
        " \n",
        "    Note:\n",
        "      1) HINT: Use PorterStemmer for stemming.\n",
        "      2) Tokenized words should not contain speacial characters.\n",
        "      3) Replace the None with output in the return statement.\n",
        "  '''\n",
        "  ### write your code here\n",
        "  pattern = r'\\b\\w+\\b'\n",
        "  stemmer=PorterStemmer()\n",
        "  words =re.findall(pattern,str1.lower())\n",
        "  stemmed_words = [stemmer.stem(word) for word in words]\n",
        "  return stemmed_words\n",
        "str1= \"Jadhav played too slowly.\"\n",
        "print(stem_words(str1))\n",
        "\n",
        " \n",
        "  ### end of code\n",
        " \n",
        "  "
      ],
      "metadata": {
        "id": "BQWYoPcdICAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b831d59-e0bd-4d15-8284-b578c487ba9c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['jadhav', 'play', 'too', 'slowli']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Problem - 5"
      ],
      "metadata": {
        "id": "lN8yOh1OINrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "#nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "def lemmatized_words(str1):\n",
        "  '''\n",
        "    Tokenize the given string into words (use regular expressions), apply lemmatization on each word and return a list of lemmatized words.\n",
        "    INPUT\n",
        "        str1: Input string.\n",
        "    OUTPUT\n",
        "        Return a list of lemmatized words\n",
        "     \n",
        "    Example:\n",
        "    input: \"He goes to theatres everytime.\"\n",
        "    output: ['He', 'go', 'to', 'theatre', 'everytime']\n",
        "    Note: \n",
        "      1) HINT: Use WordNetLemmatizer library for lemmatization.\n",
        "      2) Tokenized words should not contain speacial characters.\n",
        "      3) Replace the None with output in the return statement.\n",
        "  '''\n",
        "  ### write your code here\n",
        "  pattern =r'\\b\\w+\\b'\n",
        "  lemmatizer=WordNetLemmatizer()\n",
        "  words=re.findall(pattern,str1.lower())\n",
        "  lemma_words=[lemmatizer.lemmatize(word) for word in words]\n",
        "  return lemma_words\n",
        "str1=\"He goes to theatres everytime.\"\n",
        "print(lemmatized_words(str1))\n",
        "  ### end of code\n",
        " \n",
        "  "
      ],
      "metadata": {
        "id": "t2Q258TSIKkk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cede1db-e249-49a1-ab94-484ea6684a2e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['he', 'go', 'to', 'theatre', 'everytime']\n"
          ]
        }
      ]
    }
  ]
}